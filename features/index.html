<!--[if IE 8]> <html lang="en" class="ie8"> <![endif]-->
<!--[if IE 9]> <html lang="en" class="ie9"> <![endif]-->
<!--[if !IE]><!-->
<html lang="en">
<!--<![endif]-->

  <head>
  <title>
    
    Marian :: Features &amp; Benchmarks
    
  </title>
  <!-- Meta -->
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta name="description" content="Fast Neural Machine Translation in C++">

  <link href='http://fonts.googleapis.com/css?family=Open+Sans:300italic,400italic,600italic,700italic,800italic,400,300,600,700,800' rel='stylesheet' type='text/css'>
  <!-- Global CSS -->
  <link rel="stylesheet" href="/assets/plugins/bootstrap/css/bootstrap.min.css">
  <!-- Plugins CSS -->
  <link rel="stylesheet" href="/assets/plugins/font-awesome/css/font-awesome.min.css">
  <link rel="stylesheet" href="/assets/css/pygments/github.css">

  <!-- Theme CSS -->
  <link id="theme-style" rel="stylesheet" href="/assets/css/styles.css">
  <!-- HTML5 shim and Respond.js IE8 support of HTML5 elements and media queries -->
  <!--[if lt IE 9]>
    <script src="https://oss.maxcdn.com/html5shiv/3.7.2/html5shiv.min.js"></script>
    <script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
  <![endif]-->

  <link rel="stylesheet" href="/assets/plugins/github-fork-ribbon-css/gh-fork-ribbon.css" />
  <!--[if lt IE 9]>
    <link rel="stylesheet" href="/assets/plugins/github-fork-ribbon-css/gh-fork-ribbon.ie.css" />
  <![endif]-->

  

  
  <!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-109819276-1"></script>
<script>
    window.dataLayer = window.dataLayer || [];
    function gtag() { dataLayer.push(arguments); }
    gtag('js', new Date());
    gtag('config', 'UA-109819276-1');
</script>

  

</head>


  <body class="body-blue">
    <a class="github-fork-ribbon" href="https://github.com/marian-nmt/marian" title="Fork me on GitHub">Fork me on GitHub</a>

    <div class="page-wrapper">

    <header id="header" class="header">
  <div class="container">
    <div class="branding">
      <h1 class="logo">
        <a href="/">
          <span aria-hidden="true" class="icon_documents_alt icon"></span>
          <span class="text-highlight">Marian</span><span class="text-bold">NMT</span>
        </a>
      </h1>
      <p class="description">Fast Neural Machine Translation in C++</p>
    </div><!--//branding-->

    <ol class="breadcrumb">


 

 

 

 

 

 

 

 

 

 

 

 

 

 

 
 <li>
   <a class="page-link" href="/quickstart/">Quick start</a>
 </li>
 

 
 <li>
   <a class="page-link" href="/features/">Features &amp; Benchmarks</a>
 </li>
 

 
 <li>
   <a class="page-link" href="/docs/">Documentation</a>
 </li>
 

 
 <li>
   <a class="page-link" href="/examples/">Examples</a>
 </li>
 

 
 <li>
   <a class="page-link" href="/faq">FAQ</a>
 </li>
 

 
 <li>
   <a class="page-link" href="/publications/">Publications</a>
 </li>
 

</ol>


  </div><!--//container-->
</header><!--//header-->


    <div class="doc-wrapper">
      <div class="container">

        <div id="doc-header" class="doc-header text-center">
          <h1 class="doc-title">
            
            <i class="icon fa fa-bar-chart-o }}"></i>
            
            Features & Benchmarks
          </h1>
          <div class="meta">
            <i class="fa fa-clock-o"></i>
            Last updated: 29 June 2018
          </div>
        </div><!--//doc-header-->

        <div class="doc-body">
          <div class="doc-content">
            <div class="content-inner">

              <h2 id="features">Features</h2>

<h3 id="overview">Overview</h3>
<ul>
  <li>Up to 15x faster translation than Nematus and similar toolkits on a single GPU</li>
  <li>Up to 2x faster training than toolkits based on Theano, Tensorflow, Torch on
a single GPU</li>
  <li>Multi-GPU training and translation</li>
  <li>Batched translation on GPU and CPU</li>
  <li>Different types of models, including deep RNNs and transformers</li>
  <li>Pure C++ implementation with minimal depedencies on external packages (CUDA,
Boost)</li>
  <li>Optionally static compilation of binaries</li>
  <li>Permissive open source license (MIT)</li>
</ul>

<h3 id="model-features">Model features</h3>
<ul>
  <li>Deep RNNs with Deep Transition Cells (<a href="http://aclweb.org/anthology/W17-4710">Miceli Barone et al.
2017</a>)</li>
  <li>Transformer models (<a href="https://arxiv.org/abs/1706.03762">Vaswani et al.  2017</a>)</li>
  <li>Encoder types: bidirectional, uni-bidirectional, alternating</li>
  <li>LSTM cell instead of GRU</li>
  <li>Layer normalization (<a href="https://arxiv.org/abs/1607.06450">Ba et al. 2016</a>)</li>
  <li>Residual/skip connections between RNN layers</li>
  <li>Scaling dropout for RNN inputs and states, input and output embeddings (<a href="https://arxiv.org/abs/1512.05287">Gal
and Ghahramani, 2016</a>)</li>
  <li>Tied embeddings (<a href="https://arxiv.org/abs/1608.05859">Press and Wolf, 2017</a>)</li>
  <li>Dual-source models (<a href="https://arxiv.org/abs/1706.04138">Junczys-Dowmunt and
Grundkiewicz, 2017</a>)</li>
  <li>Deep RNN and transformer language models</li>
</ul>

<h3 id="training-features">Training features</h3>
<ul>
  <li>Adjusting mini-batch size dynamically to maximize usage of available or
bounded memory</li>
  <li>Asynchronous/synchronous parallel SGD (data parallelism) with vanilla SGD,
Adagrad, or Adam</li>
  <li>Different regularization techniques, such as dropout, exponential smoothing,
and label smoothing</li>
  <li>Multi-GPU validation and in-training translation</li>
  <li>Exposed optimizer parameters</li>
  <li>Decaying and warmup strategies for learning rate</li>
  <li>Custom word embeddings from <a href="https://github.com/dav/word2vec">word2vec</a></li>
  <li>Guided alignment to guide attention</li>
  <li>Language model pretraining</li>
</ul>

<h3 id="translation-features">Translation features</h3>
<ul>
  <li>Batched translation on single and multiple GPU/CPUs</li>
  <li>Ensembling models of different types</li>
  <li>C++ web-socket service for translation</li>
  <li>Length normalization</li>
  <li>Generating hard alignments from deep RNN models</li>
  <li>Rescoring n-best lists and parallel files</li>
</ul>

<h3 id="experimental-features">Experimental features</h3>
<p>Experimental features are available only in the Marian decoder.</p>

<ul>
  <li>Character-level convolutional models (<a href="https://arxiv.org/abs/1610.03017">Lee et al.
2017</a>)</li>
  <li>Multi-node GPU training</li>
</ul>

<h2 id="benchmarks">Benchmarks</h2>

<h3 id="translation-speed">Translation speed</h3>

<p>The models used for the translation speed benchmarks have been described in
the <a href="http://workshop2016.iwslt.org/downloads/IWSLT_2016_paper_4.pdf">IWSLT paper</a>.</p>

<p><img src="/assets/images/translation_speed.png" alt="Translation speed #1" /></p>

<p>We ran our experiments on an Intel Xeon E5-2620 2.40GHz server with four NVIDIA
GeForce GTX 1080 GPUs.We present the words-per-second ratio for our NMT models
using Marian and Nematus, executed on the CPU and GPU. For the CPU version we
use 16 threads, translating one sentence per thread. We restrict the number of
OpenBLAS threads to 1 per main Nematus thread. For the GPU version of Nematus
we use 5 processes to maximize GPU saturation. As a baseline, the phrase-based
model reaches 455 words per second using 16 threads.</p>

<p>The CPU-bound execution of Nematus reaches 47 words per second while the
GPU-bound achieved 270 words per second. In similar settings, CPU-bound Marian
is three times faster than Nematus CPU, but three times slower than Moses. With
vocabulary selection (systems with asteriks) we can nearly double the speed of
Marian CPU. The GPU-executed version of Marian is more than three times faster
than Nematus and nearly twice as fast as Moses, achieving 865 words per second,
with vocabulary selection we reach 1,192. Even the speed of the CPU version
would already allow to replace a Moses-based SMT system with an Marian-based
NMT system in a production environment without severely affecting translation
throughput.</p>

<p><img src="/assets/images/translation_speed2.png" alt="Translation speed #2" /></p>

<p>Amun also features “batched” translation, i.e. multiple sentences are being
translated at once on a single GPU. Since computation time for matrix products
on the GPU increases sub-linearly with regard to matrix size, we can take
advantage of this by pushing multiple translation through the neural network.
For the same models as above and a batch-size of 200 (beam-size 5) we achieve
over 5000 words per second on one GPU. This scales linearly to the number of
GPUs used. As before, the asteriks marks systems with vocabulary filtering.
Systems “Single” and “Single*” are the same as two best systems in the first
graph.</p>

<h3 id="training-speed">Training speed</h3>

<p>We also compare training speed between a number of popular toolkits and Marian.
As Marian is still early work, we expect speed to improve with future optimizations.
The numbers reported in this section have been computed on a single GPU.</p>

<div class="multiple-images">
  <img alt="Training speed #1" src="/assets/images/train.speed500.png" />
  <img att="Training speed #2" src="/assets/images/train.speed1024.png" />
</div>

<p>We compare models with standard settings and comparable embedding, hidden layer and batch sizes.
The first graph corresponds to the model parameters described in the
<a href="https://arxiv.org/abs/1701.02810">OpenNMT paper</a>,
the second corresponds to Nematus default settings for embedding and hidden layer
sizes. In both cases we use a vocabulary size of 32,000 subword units. The models were trained
on German-English WMT data. Nematus-array is Nematus run with the new Cuda backend libgpuarray.
Blue bars describe training speed on a NVIDIA GTX 1080 GPU, green bars on a Titan X with Pascal
architecture.</p>

<h3 id="multi-gpu-training">Multi-GPU training</h3>

<p>Marian’s training framework provides multi-GPU training via
synchronous/asynchronous SGD and data parallelism (copies of the full model on
each GPU).
We benchmarked the <a href="/examples/training/">Romanian-English example</a> on a machine
with 8 NVIDIA P100 GPUs. Training speed increases with each GPU instance.
The increase for synchronous SGD is sub-linear, but it may allow to achieve
lower cross-entropy score for certain model types, which may be not achievable
with asynchronous SGD.</p>

<p width="90%"><img src="/assets/images/multi_gpu.png" alt="Multi GPU" /></p>

<p>Our current version of asynchronous SGD is delay-free, i.e. that all (sharded)
gradients are propagated to all GPUs for each update. In the future we will
introduce delayed updates which should result in a more linear performance
increase with each additional GPU.</p>


            </div><!--//content-inner-->
          </div><!--//doc-content-->

          <div class="doc-sidebar hidden-xs">
            <nav id="doc-nav"></nav>
          </div><!--//doc-sidebar-->

        </div><!--//doc-body-->

      </div><!--//container-->
    </div><!--//doc-wrapper-->

    </div><!--//page-wrapper-->

    <footer id="footer" class="footer text-center">
  <div class="container">
    <p>
     Marian - an efficient Neural Machine Translation framework written in pure C++.</br>
      Mainly developed at the Adam Mickiewicz University in Poznań and at the University of Edinburgh.
    </p>
    <p><a href="https://github.com/marian-nmt/marian">Marian</a> is licensed under the <a href="https://github.com/marian-nmt/marian/LICENSE">MIT license</a>.</p>
    <p><small class="copyright">Based on the theme PrettyDocs designed by <a href="http://themes.3rdwavemedia.com/" targe="_blank">Xiaoying Riley</a> with modifications.</small></p>
  </div><!--//container-->
</footer><!--//footer-->

    <!-- Main Javascript -->
<script type="text/javascript"> localStorage.clear();</script>

<script type="text/javascript" src="/assets/plugins/jquery-1.12.3.min.js"></script>
<script type="text/javascript" src="/assets/plugins/bootstrap/js/bootstrap.min.js"></script>
<script type="text/javascript" src="/assets/plugins/jquery-scrollTo/jquery.scrollTo.min.js"></script>
<script type="text/javascript" src="/assets/plugins/jquery-match-height/jquery.matchHeight-min.js"></script>

<script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>

<script type="text/javascript" src="/assets/js/main.js"></script>
<script type="text/javascript" src="/assets/js/toc.js"></script>


  </body>
</html>
